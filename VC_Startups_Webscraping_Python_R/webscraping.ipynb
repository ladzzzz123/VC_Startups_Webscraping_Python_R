{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import codecs\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "url = 'http://www.seed-db.com/companies/funding?value=1000000' # get the website we'll scrape\n",
    "companies = BeautifulSoup(requests.get(url).text, 'lxml') # tranform it to 'beautifulsoup' type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# access the table with target data\n",
    "table = companies.find('tbody')\n",
    "rows = table.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a list to store data\n",
    "final_result = []\n",
    "\n",
    "# define the function to get data about seed accelerators with corresponding links\n",
    "def accelerator_info(link, startup):\n",
    "    accel_info = BeautifulSoup(requests.get(link).text, 'lxml')\n",
    "    body = accel_info.find('body')\n",
    "    \n",
    "    introduction = body.find_all('div', {'class': 'container-fluid'})[1].find('div', {'class': 'col-md-12'})\n",
    "    \n",
    "    basic_info = introduction.find_all('div', {'class': 'row'})[0].find('div', {'class': 'col-md-4'})\n",
    "    startup['accel_website'] = basic_info.find('a')['href']\n",
    "    startup['accel_estb_yr'] = re.findall('[0-9]+', basic_info.find_all('p')[1].text)\n",
    "    startup['accel_add'] = basic_info.find_all('p')[2].text\n",
    "    \n",
    "    funded_info = introduction.find_all('div', {'class': 'row'})[1].find_all('div', {'class': 'col-md-6'})[1]\n",
    "    \n",
    "    startup['accel_num_funded'] = re.findall('[0-9]+', funded_info.find_all('p')[4].text.replace(',', ''))\n",
    "    startup['accel_num_exited'] = re.findall('[0-9]+', funded_info.find_all('p')[5].text.replace(',', ''))\n",
    "    startup['accel_amt_exited'] = re.findall('[0-9]+', funded_info.find_all('p')[6].text.replace(',', ''))\n",
    "    startup['accel_amt_funded'] = re.findall('[0-9]+', funded_info.find_all('p')[7].text.replace(',', ''))\n",
    "   \n",
    "    return startup\n",
    "\n",
    "# read data row by row from the website\n",
    "i = 0\n",
    "for row in rows:\n",
    "    try:\n",
    "        company = {} # create a dictionary to store information of every row\n",
    "        tds = row.find_all('td') # search for the data\n",
    "\n",
    "        # extract information form the web\n",
    "        state = tds[0].text.replace('\\n', '')\n",
    "        name = tds[1].text.replace('\\n', '')\n",
    "        website = tds[2].find('a')['href']\n",
    "        funding = tds[6].text.replace('$', '').replace(',', '').strip()\n",
    "        rounds = tds[7].text\n",
    "        accelerator = tds[3].text\n",
    "\n",
    "        # get the information of corresponding accelerators \n",
    "        accel_link = 'http://seed-db.com/' + tds[3].find('a')['href']\n",
    "        company = accelerator_info(accel_link, company)\n",
    "\n",
    "        # store the result into the dictionary\n",
    "        company['state'] = state\n",
    "        company['name'] = name\n",
    "        company['website'] = website\n",
    "        company['seed_accelartor'] = accelerator\n",
    "        company['funding'] = funding\n",
    "        company['rounds'] = rounds\n",
    "    \n",
    "        # add information of every row as an element to the list\n",
    "        final_result.append(company)\n",
    "        i = i+1\n",
    "        print '############### %d ############' % i\n",
    "    \n",
    "    except:\n",
    "        print '********************** Error *****************'\n",
    "        time.sleep(10) # restart\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store data into the file\n",
    "f = codecs.open('companies.csv', 'w', 'utf-8') # some variables will be formatted with R\n",
    "final_data = pd.DataFrame(final_result)\n",
    "final_data.to_csv('companies.csv')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nda\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
